
Hi, 

I'm Eva - an ecologist-turned-data scientist working in the public sector. 

By day, I deliver insights into the environment through data visualisations, statistics and machine learning techniques. 

In my downtime, I am lucky to be able to participate in many non-profit ventures including volunteering at my local [codebar](https://codebar.io/) as well as both DataDives and book clubs with the UK chapter of [DataKind](https://www.datakind.org/chapters/datakind-uk). 

I am always on the look out for opportunities to engage with data science practitioners, educators and researchers with a grand plan to harness the power of data for good!


# EDUCATIONAL RESOURCES:

## **Statistical modelling into Neural Networks**
I used to teach once upon a time so here are some resources for those finding their way into statistics, data science and machine learning. Most scripts include visualisation techniques.

#### 1. Linear Regression in [R] and [Python]
            These resources show how to determine (and predict) a linear relationship between variables by fitting a straight line through data. This and further resources start from first principles and later use built in packages/modules.
            
#### 2. Logistic Regression in [R] and [Python]
            Want to know how to fit a binary classifier? These scripts demonstrate the power of logistic regression for calculating the probability of one of two events (e.g. presence vs absence, control vs treatment) 

#### 3. Simple Neural Networks [R] and [Python]
            This work sets up the foundations for building Deep Neural Networks, following much of the same approach explained in Logistic Regression. By the end you'll see the power of switching to Neural Networks to reveal non-linear patterns. 
            
**Stil to come: More on Deep Neural Networks, Convolutional and Recurrent Neural Networks** 

## **Further Concepts**
If you have ran the scripts in Linear Regression and Logistic Regression above, you'll be familiar with some of these concepts. These scripts and presentations go into further detail.

#### 1. Regularisation in [R]
             This is a great tool to have for reducing overfitting in statistical models and in many machine learning methods. The script presents an example of lasso and ridge regularisation using regression packages in R. 
             
#### 2. Gradient Descent [R] and [Python]
             Gradient Descent is a key method used to fit statistics and machine learning models where normal matrix calculations are too computationally expensive (e.g. where you have 10s or 100s of predictors)

## **Bayesian Statistics (Still to come)**
While the above are fairly common fitting procedures that often use frequentist methods, I will soon also present similar analyses fitting Bayesian models with the Stan programming language (interfaced with R and python)


### Contact
_Keen to find out more?_
Find me on [twitter](https://twitter.com/eva_wm) or [email](mailto:emuiruri25@gmail.com)




